# -*- coding: utf-8 -*-
"""RAGAs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10ck26qKH-a1TBFe0-CbgD0s_kO376PtQ
"""

from google.colab import userdata
OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')

import os
os.environ["OPENAI_API_KEY"]= OPENAI_API_KEY

!pip install -q langchain
!pip install -q ragas
!pip install -q faiss-cpu
!pip install -q langchain-openai
!pip install -q tiktoken

from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI

## Load the Data
loader = TextLoader("/content/state_of_the_union.txt")
document = loader.load()

## Chunking the Data

text_splitter = RecursiveCharacterTextSplitter(chunk_size= 500, chunk_overlap= 50)
chunks = text_splitter.split_documents(document)

from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()

from langchain_community.vectorstores import FAISS

vectordb = FAISS.from_documents(chunks, embeddings)

retriever = vectordb.as_retriever()

# Defining LLM

llm = ChatOpenAI(temperature= 0.6)

## Define Prompt Template

template = """You are an assistant for question-answering tasks.
Use the following pieces of retrieved context to answer the question.
If you don't know the answer, just say that you don't know.
Use two sentences maximum and keep the answer concise.
Question: {question}
Context: {context}
Answer:
"""





from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser

prompt = ChatPromptTemplate.from_template(template)

## Setting UP RAG Pipeline

chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

chain.invoke("What did president say about Justic Breyer?")

questions = ["what did the President say about Justic Breyer?",
           "What did the President say abou Intel's CEO?",
           "What did the President say about gun violence?"]

ground_truth = ["The president said that Justice Breyer has dedicated his life to serve the country and thanked him for his service.",
              "The president said that Pat Gelsinger is ready to increase Intel's investment to $100 billion.",
              "The president asked Congress to pass proven measures to reduce gun violence."]

answer = []
content = []

# Inference

for query in questions:
  answer.append(chain.invoke(query))
  content.append([docs.page_content for docs in retriever.get_relevant_documents(query)])

## To dict
data = {
    "question": questions,
    "ground_truth": ground_truth,
    "answer": answer,
    "contexts": content
}

from datasets import Dataset
dataset = Dataset.from_dict(data)

dataset

from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_recall,
    context_precision,
)

result = evaluate(dataset= dataset,
                  metrics = [
                      context_precision,
                      context_recall,
                      faithfulness,
                      answer_relevancy],
                  llm = llm,
                  embeddings =embeddings
                  )

result

df = result.to_pandas()

df

"""after evaluating the llm we can apply agents"""

from langchain.tools import Tool

def search_web(query: str) -> str:
    # Example function to simulate a web search
    return f"Results for query: {query}"

search_tool = Tool(
    name="WebSearch",
    func=search_web,
    description="Performs a web search for a given query,You are an assistant for question-answering tasks"
)

from langchain.agents import initialize_agent, AgentType

# Add your tools here
tools=[wiki,arxiv,retriever_tool]

# Create the agent
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

## Agent Executer
from langchain.agents import AgentExecutor
agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)
agent_executor

agent_executor.invoke({"query":"What did president say about Justic Breyer"})